{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a666bf-098b-4eb1-9845-43118e9105b9",
   "metadata": {},
   "source": [
    "# DataCamp - Working with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3427779-ba18-412e-86df-d1e0065ff722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data folder\n",
    "data_folder = \"/Users/miguelbaptista/Library/CloudStorage/OneDrive-Personal/Data_Science/Python/MOOC/DataCamp/ficheiros_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8609c2c0-7cd7-4df2-91e9-014c52eea5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74389c85-e539-40e6-9e2a-99e94b2b5d3c",
   "metadata": {},
   "source": [
    "# 0) Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5615ea-8595-40d3-8342-13a05c611b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load course files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc5bb69-cdb2-400c-8506-72e5646a626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI version:  1.51.2\n"
     ]
    }
   ],
   "source": [
    "# Usar os meus dados\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# openai library version\n",
    "print(\"OpenAI version: \", openai.__version__)\n",
    "\n",
    "# key\n",
    "OPENAI_API_KEY=''\n",
    "\n",
    "# client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805ff23-e151-44c3-90f6-9602e80cf8c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f897fa4-072e-4cb2-b1a1-a619ffe6372e",
   "metadata": {},
   "source": [
    "# 1) Introduction to the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2681bb-53be-44e3-9816-24e0f6bcb931",
   "metadata": {},
   "source": [
    "## What is the OpenAI API?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488382f3-9a4b-4646-bdb3-4d3eed33faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vÃ­deo\n",
    "\n",
    "# API -> Application Programming Interface\n",
    "# Request -> Response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167ef66-4589-4b66-8e21-8bc7dbbe59e2",
   "metadata": {},
   "source": [
    "**Your first OpenAI API request!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6067959-fcc7-42fc-8a95-9d107bee6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the OpenAI API is valuable for developers for several reasons:\n",
      "\n",
      "1. **Access to Advanced AI Models**: The OpenAI API provides access to state-of-the-art AI models, such as GPT-3 and later versions, which can perform a wide range of tasks including natural language understanding, text generation, code generation, and more. This allows developers to utilize cutting-edge technology in their applications.\n",
      "\n",
      "2. **Enhanced Product Functionality**: By integrating AI capabilities, developers can enhance their products and\n"
     ]
    }
   ],
   "source": [
    "# prompt example\n",
    "prompt_example = \"\"\"Why is learning the OpenAI API valuable for developers?\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=100,\n",
    "  \n",
    "    # Enter your prompt\n",
    "    messages=[{\"role\": \"user\", \n",
    "               \"content\": prompt_example}]\n",
    ")\n",
    "\n",
    "# print response only\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82ab3795-6b4f-4746-bc80-30e90ea577bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', 'chatcmpl-BKqkmu2wJsSH6gUwFj95teraSdggn')\n",
      "('choices', [Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Learning the OpenAI API is valuable for developers for several reasons:\\n\\n1. **Access to Advanced AI Models**: The OpenAI API provides access to state-of-the-art AI models, such as GPT-3 and later versions, which can perform a wide range of tasks including natural language understanding, text generation, code generation, and more. This allows developers to utilize cutting-edge technology in their applications.\\n\\n2. **Enhanced Product Functionality**: By integrating AI capabilities, developers can enhance their products and', refusal=None, role='assistant', function_call=None, tool_calls=None, annotations=[]))])\n",
      "('created', 1744309044)\n",
      "('model', 'gpt-4o-mini-2024-07-18')\n",
      "('object', 'chat.completion')\n",
      "('service_tier', 'default')\n",
      "('system_fingerprint', 'fp_64e0ac9789')\n",
      "('usage', CompletionUsage(completion_tokens=100, prompt_tokens=18, total_tokens=118, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# Complete response\n",
    "for i in response:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87624e9a-a46f-4791-978a-8284ac31a0be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33aef038-38c6-41bb-84eb-ff782736cdd1",
   "metadata": {},
   "source": [
    "## Making requests to the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba6d6cfb-b965-4fc5-b2b2-5bbcb44536fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vÃ­deo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4713817e-7082-41f0-af44-0ec7d270cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Acceptance of Job Offer for AI Engineer Position\n",
      "\n",
      "Dear [Hiring Manager's Name],\n",
      "\n",
      "I hope this message finds you well. I would like to express my sincere gratitude for the offer to join [Company Name] as an AI Engineer. I am thrilled to accept the position and am eager to contribute to the innovative projects your team is working on.\n",
      "\n",
      "I appreciate the confidence you have placed in me, and I am looking forward to collaborating with such a talented group of individuals. Please let me know if there are any further steps I need to complete prior to my start date on [Start Date].\n",
      "\n",
      "Thank you once again for this wonderful opportunity. I am excited to embark on this journey with [Company Name].\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Phone Number]  \n",
      "[Your Email Address]  \n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "prompt = \"Write a polite reply accepting an AI Engineer job offer.\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73580e6b-cd4a-4385-bf8a-3cdf20c74611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a professional announcement you can use for your LinkedIn post:\n",
      "\n",
      "---\n",
      "\n",
      "ðŸš€ Exciting News! ðŸš€\n",
      "\n",
      "I am thrilled to share that I have accepted a new position as an AI Engineer! ðŸ’»âœ¨ \n",
      "\n",
      "In this role, I will be diving deep into the world of artificial intelligence, working on innovative projects that push the boundaries of technology. I'm eager to collaborate with an amazing team and contribute to the development of cutting-edge solutions that make a difference.\n",
      "\n",
      "I want to thank everyone who has supported me on this journeyâ€”mentors, colleagues, and friends. Your encouragement and guidance have been invaluable!\n",
      "\n",
      "Looking forward to this new chapter and the challenges ahead. Letâ€™s connect and keep the conversation going about the fascinating world of AI! \n",
      "\n",
      "#NewJob #AI #ArtificialIntelligence #CareerMove #Excited\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to customize it to reflect your personality and specific experiences!\n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "prompt = \"Announce my new AI Engineer role on LinkedIn.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  # Specify the model\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    # Assign the correct role\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": prompt}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf64fea-cda7-4e8b-b2e8-8f427e54cf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the Pomodoro Technique: Work for 25 minutes, then take a 5-minute break. After four cycles, take a longer break of 15-30 minutes. This method helps maintain focus, reduces mental fatigue, and boosts overall productivity.\n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": \"Quick productivity tip.\"}]\n",
    ")\n",
    "\n",
    "# Extract the content from the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ef259-9362-4a8c-ac70-0b72bf5e8566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc4b03fd-7962-4926-a5a6-6820e0594637",
   "metadata": {},
   "source": [
    "# 2) OpenAI's Text and Chat Capabilities / Prompting OpenAI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93e9e7-fdc2-4603-8962-ade9f731cfc8",
   "metadata": {},
   "source": [
    "## Generating and transforming text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e976472-9bb6-4441-bdc8-c3f3d2da8c9e",
   "metadata": {},
   "source": [
    "#### - temperature parameter (0 to 2) [default is 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496e7e5f-e6b4-46b9-b5df-fe4b5d555bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"...you never know what you're gonna get.\" This iconic line from the movie \"Forrest Gump\" metaphorically expresses the unpredictability of life. Just like a box of assorted chocolates, life's experiences can be diverse and surprising, bringing both joy and challenges. It's a reminder to embrace the uncertainty and variety of our journeys. Do you have a particular insight or experience related to this quote that you'd like to share?\n"
     ]
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "# vÃ­deo\n",
    "\n",
    "# Controlling response randomness \n",
    "# - \"temperature\": control on determinism --> ranges from 0 (highly deterministic) to 2 (very random)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": \"Life is like a box of chocolates.\"}],\n",
    "  temperature=1.25\n",
    ")\n",
    "\n",
    "# Extract the content from the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85777b1-2858-4384-99fe-a258b553f834",
   "metadata": {},
   "source": [
    "#### - max_tokens parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2adde810-6d7c-44da-9ed0-744793b260b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whispers of the code,  \n",
      "Silent wisdom takes its form,  \n",
      "Dreams of circuits hum.\n"
     ]
    }
   ],
   "source": [
    "#%%script false --no-raise-error\n",
    "\n",
    "# vÃ­deo (continuaÃ§Ã£o)\n",
    "\n",
    "# Content transformation\n",
    "#  Changing text based on an instruction:\n",
    "#    - Find and replace\n",
    "#    - Summarization\n",
    "#    - Copyediting\n",
    "\n",
    "\n",
    "# Default max_tokens (short by default)\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \n",
    "             \"content\": \"Write a haiku about AI.\"}],\n",
    "  max_tokens=30\n",
    ")\n",
    "\n",
    "# Extract the content from the response\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# Cost depends on amount of inout and output text and models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f984843d-aaea-45ed-8f23-a74d5b3af92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc4a50-82e0-4418-8a01-9d1c35aff5bd",
   "metadata": {},
   "source": [
    "#### Find and replace/adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cf1ef56-75b5-42b5-9a75-a202670bd551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plane is a vehicle that is typically powered by jet engines or propellers. It has fixed wings and is designed to carry passengers and/or cargo through the air. Planes have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods over long distances. Planes are often associated with adventure, connectivity, and the ability to traverse vast distances.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, \n",
    "and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, \n",
    "and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. \n",
    "Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "    \n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_tokens=100\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d247b6-542a-434c-a62f-a9bd4b66a37b",
   "metadata": {},
   "source": [
    "#### Text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5292814c-4979-4a2c-84ee-56f1a18ac6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Investment involves committing capital to various options (e.g., stocks, bonds, real estate) with the expectation of generating income or profit, requiring careful analysis of risks and potential rewards.  \n",
      "- Diversifying investment portfolios can minimize risk and enhance long-term returns, making informed investing crucial for wealth building and financial security.\n"
     ]
    }
   ],
   "source": [
    "# Use a maximum of 400 tokens and make the response more deterministic than the default.\n",
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "\n",
    "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income\n",
    "or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, \n",
    "precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of \n",
    "potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. \n",
    "Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, \n",
    "generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=400,\n",
    "  temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be8314-0b44-4eb3-9265-93521604b89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7c5a535-1498-42a4-833a-b9e6b5f10b3f",
   "metadata": {},
   "source": [
    "#### Calculating the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39276a3-eed2-4289-b1a4-63a28f163c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost: 0.0002631$\n"
     ]
    }
   ],
   "source": [
    "max_completion_tokens = 400\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    max_completion_tokens=max_completion_tokens\n",
    ")\n",
    "\n",
    "input_token_price = 0.15 / 1_000_000\n",
    "output_token_price = 0.6 / 1_000_000\n",
    "\n",
    "# Extract token usage\n",
    "input_tokens = response.usage.prompt_tokens\n",
    "output_tokens = max_completion_tokens\n",
    "\n",
    "# Calculate cost\n",
    "cost = (input_tokens * input_token_price + output_tokens * output_token_price)\n",
    "print(\"Estimated cost: {}$\".format(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f5ac0-fff1-49c7-b1ab-f341d645388a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2cf9bf7-c24a-4340-bd4a-050bd3685e9f",
   "metadata": {},
   "source": [
    "#### Content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d6d770a-1f6a-4ef1-b0d2-514d23e3a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Savor the Moments, Relish the Flavor!\"\n"
     ]
    }
   ],
   "source": [
    "# Create a request to create a slogan for a new restaurant; set the maximum number of tokens to 100.\n",
    "prompt = \"\"\"Create a slogan for a new restaurant\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c42fa-6ab5-45e0-8b04-b46788e57ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54809a6a-6cbb-4d97-9c3a-716d191f7930",
   "metadata": {},
   "source": [
    "#### Generating a product description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ed43c78-613f-4699-bba9-de73a0ef6dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**SonicPro Headphones: Elevate Your Listening Experience**\n",
      "\n",
      "Introducing the SonicPro Headphones, where cutting-edge technology meets unparalleled comfort. Designed for audiophiles and casual listeners alike, these headphones are your ultimate companion for immersive sound experiences.\n",
      "\n",
      "**Active Noise Cancellation (ANC):** Immerse yourself in your favorite tunes without distractions. Our advanced Active Noise Cancellation technology effectively blocks out ambient noise, allowing you to enjoy crystal-clear audio whether you're on a bustling commute, at a busy cafÃ©, or simply relaxing at home. Focus on what matters mostâ€”your music.\n",
      "\n",
      "**40-Hour Battery Life:** Say goodbye to frequent charging! With an impressive 40-hour battery life on a single charge, the SonicPro headphones are built for endurance. Whether you're\n"
     ]
    }
   ],
   "source": [
    "# Create a detailed prompt\n",
    "prompt = \"\"\"\n",
    "Generate a product description for SonicPro headphones, including:\n",
    "- Active noise cancellation (ANC)\n",
    "- 40-hour battery life\n",
    "- Foldable design\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    # Experiment with max_completion_tokens and temperature settings\n",
    "    max_completion_tokens=150,\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be43116-e2d5-4fd7-bd78-9b3caa2d6142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8be05-2296-4083-bbc4-8d748efffcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "637bf286-2544-460b-aa5b-2f08e0156dcf",
   "metadata": {},
   "source": [
    "## Sentiment analysis & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14a568e2-80c1-407f-b5ec-cf3b180a8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vÃ­deo\n",
    "\n",
    "# Classification tasks:\n",
    "# - Identifying the language in the text\n",
    "# - Categorization\n",
    "# - Classifying sentiment\n",
    "\n",
    "# Zero-shot vs One-shot vs Few-shot prompting\n",
    "# - Zero-shot prompting: no examples provided\n",
    "# - One-shot prompting: one example provided (in-context learning)\n",
    "# - Few-shot prompting: multiple examples provided (in-context learning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983bcb46-ee8b-45bc-bb4f-6d23a1bd4898",
   "metadata": {},
   "source": [
    "#### Classifying text sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9703210-4763-48fe-8c4d-83395a5761fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positive\n",
      "2. Negative\n",
      "3. Neutral\n",
      "4. Positive\n"
     ]
    }
   ],
   "source": [
    "# Define a multi-line prompt to classify sentiment\n",
    "prompt = \"\"\"Classify as negative, positive or neutral:\n",
    "\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5618d3a-9293-4383-8cb8-616f6ae068f6",
   "metadata": {},
   "source": [
    "#### Categorizing companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df292748-05ec-49fe-95c2-fa2203605ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hereâ€™s a categorization of the listed companies based on their primary industry sectors:\n",
      "\n",
      "### Technology\n",
      "- **Apple**: Consumer Electronics, Software\n",
      "- **Microsoft**: Software, Cloud Computing\n",
      "- **Alphabet (Google)**: Internet Services, Technology\n",
      "- **Amazon**: E-commerce, Cloud Computing\n",
      "- **NVIDIA**: Semiconductors, Graphics Processing Units (GPUs)\n",
      "- **Meta (Facebook)**: Social Media, Technology\n",
      "\n",
      "### Energy\n",
      "- **Saudi Aramco\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt for the categorization\n",
    "prompt = \"\"\"Categorize the following companies: \n",
    "Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f19bca65-fa86-4fd0-8201-c6db119d0fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hereâ€™s the categorization of the companies based on the provided categories:\n",
      "\n",
      "**Tech:**\n",
      "- Apple\n",
      "- Microsoft\n",
      "- Alphabet\n",
      "- Amazon\n",
      "- NVIDIA\n",
      "- Meta\n",
      "\n",
      "**Energy:**\n",
      "- Saudi Aramco\n",
      "- Tesla (also categorized as Tech due to its electric vehicle technology)\n",
      "\n",
      "**Luxury Goods:**\n",
      "- LVMH\n",
      "\n",
      "**Investment:**\n",
      "- Berkshire Hathaway \n",
      "\n",
      "Let me know if you need further assistance!\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt for the categorization\n",
    "prompt = \"\"\"Categorize the following companies alongside 4 categories (Tech, Energy, Luxury Goods, or Investment): \n",
    "Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d2029-5edb-473b-ad94-8fa29623f724",
   "metadata": {},
   "source": [
    "Categorically commendable! Providing a more specific prompt gave you much greater control over the model's response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b249d-1967-4438-b116-4cf6d8bcec30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa2a7135-faaf-4be9-9ae3-b2c2074b1b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the sentiment classifications for the provided statements:\n",
      "\n",
      "1. Comfortable, but not very pretty = 2\n",
      "2. Love these! = 5\n",
      "3. Unbelievably good! = 5\n",
      "4. Shoes fell apart on the second use. = 1\n",
      "5. The shoes look nice, but they aren't very comfortable. = 2\n",
      "6. Can't wait to show them off! = 5\n"
     ]
    }
   ],
   "source": [
    "# Add the final example\n",
    "prompt = \"\"\"Classify sentiment as 1-5 (negative to positive):\n",
    "1. Comfortable, but not very pretty = 2\n",
    "2. Love these! = 5\n",
    "3. Unbelievably good! = \n",
    "4. Shoes fell apart on the second use. = \n",
    "5. The shoes look nice, but they aren't very comfortable. = \n",
    "6. Can't wait to show them off! = \"\"\"\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}], max_completion_tokens=100)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a942e9-846b-4c20-98bc-1d1db2ba0a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2930d-e7aa-48a9-b44b-1f8c91bd8340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c47d39e7-88dc-4c21-91dc-9a567285e204",
   "metadata": {},
   "source": [
    "# 3) Building Conversations with the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0014d6-be70-4521-b9c4-166c64523570",
   "metadata": {},
   "source": [
    "## Chat completions with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f904d568-3e5a-480b-b33a-529aaa172ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vÃ­deo\n",
    "\n",
    "# The Chat Completions endpoint\n",
    "\n",
    "# Single-turn tasks: (1 input and 1 ouput)\n",
    "# - Text generation\n",
    "# - Text transformation\n",
    "# - Classification\n",
    "\n",
    "\n",
    "# Multi-turn conversations (next video)\n",
    "# - Build on previous prompts and responses\n",
    "\n",
    "\n",
    "# Roles --> at the heart of how chat models function\n",
    "# - user (what we've used so far): **instruct** the assistant\n",
    "# - system: controls assistant's **behavior**\n",
    "# - assistant: response to user instruction\n",
    "#   - can also be written by the user to provide examples\n",
    "\n",
    "# FOR NOW, WE'LL ONLY LOOK AT DIFFERENT ROLES FOR SINGLE-TURN TASKS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0fd1c6e-bbba-4739-975c-f09621c992a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutable objects can be changed after their creation, meaning you can modify their content without creating a new object. Examples include lists and dictionaries in Python.\n",
      "\n",
      "Immutable objects, on the other hand, cannot be changed once created. Any modification results in the creation of a new object. Examples include tuples and strings in Python.\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "system_prompt=\"\"\"Your are a data science tutor who speaks concisely\"\"\"\n",
    "user_prompt=\"\"\"What is the difference between mutable and immutable objects?\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}],\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5328366b-5267-4419-b20d-e0d2cc8a5fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34d5a541-e5d4-4db3-9fec-ec16b23c5f79",
   "metadata": {},
   "source": [
    "#### Chat completion roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "748907ee-51ae-43d5-9574-ce475edb68dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both `for` loops and `while` loops are control flow statements that allow you to execute a block of code multiple times, but they do so in different ways. Hereâ€™s a breakdown of the differences between them:\n",
      "\n",
      "### For Loop:\n",
      "1. **Purpose**: A `for` loop is typically used when the number of iterations is known beforehand or when iterating over a sequence (like a list or a range).\n",
      "  \n",
      "2. **Syntax**: The syntax generally includes initialization, condition, and iteration in one line.\n",
      "   ```python\n",
      "   for variable in iterable:\n",
      "       # code block\n",
      "   ```\n",
      "   For example:\n",
      "   ```python\n",
      "   for i in range(5):\n",
      "       print(i)\n",
      "   ```\n",
      "   This will print numbers\n"
     ]
    }
   ],
   "source": [
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  max_tokens=150,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor.\"},\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Â Extract the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ba714-9989-4d00-83c6-aad88fb029bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177900d7-7d1c-4a7c-ad81-927fe206996c",
   "metadata": {},
   "source": [
    "#### Adding guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "706f9bfd-fe53-4d06-beba-eec0bbb813f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apologies, to focus on languages, we no longer create learning plans on other topics.\n"
     ]
    }
   ],
   "source": [
    "# One of the most popular uses of system messages is to add guardrails, which places restrictions on model outputs.\n",
    "\n",
    "sys_msg = \"\"\"You are a study planning assistant that creates plans for learning new skills.\n",
    "If these skills are non related to languages, return the message:\n",
    "'Apologies, to focus on languages, we no longer create learning plans on other topics.'\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": sys_msg},\n",
    "    {\"role\": \"user\", \"content\": \"Help me learn to rollerskating.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e66ab-3a5a-4ff7-bfb5-af9f8ef8db21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dc9b01c-7088-422d-aac2-7f33a1de68be",
   "metadata": {},
   "source": [
    "#### Code explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d483c343-83a1-4696-ad1a-757146aa3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Python code calculates and prints the average height of the individuals listed in the `heights_dict` dictionary using NumPy's `mean` function.\n"
     ]
    }
   ],
   "source": [
    "# Create a request to send instruction to the gpt-4o-mini model (using a system message is optional here).\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = heights_dict.values()\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": instruction}\n",
    "     ],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d39c70-f8ee-4d10-9194-2b8d33fb062f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cce9242-6745-4f80-bf04-2b5b49cb90df",
   "metadata": {},
   "source": [
    "#### Adding assistant messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97ff9bd0-1646-4971-a9ab-002c695c0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greece is a southeastern European country known for its rich history and contributions to Western civilization. The capital city is Athens, which is home to significant ancient landmarks like the Acropolis. Greece comprises numerous islands, with Crete being the largest. The country is famous for its Mediterranean climate, stunning landscapes, and cultural heritage, including mythology, philosophy, and the arts. The official language is Greek, and the currency is the euro.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # Add a user and assistant message for in-context learning\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful Geography tutor that generates concise summaries for different countries.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a quick summary of Portugal.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Portugal is a country in Europe that borders Spain. The capital city is Lisboa.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Give me a quick summary of Greece.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793cc3f-5879-4ec8-8e1d-b7148e71a310",
   "metadata": {},
   "source": [
    "#### More assistant messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b78f05c5-b54e-4788-84cc-2a4cd04dc398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greece is a country in Southeast Europe, known for its rich history and ancient civilization. It is bordered by Albania, North Macedonia, and Bulgaria, and has a extensive coastline along the Aegean, Ionian, and Mediterranean Seas. The capital city is Athens. Greece is famous for its contributions to art, philosophy, and politics, as well as its picturesque islands and traditional cuisine.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add in the extra examples and responses\n",
    "   messages=[\n",
    "       {\"role\": \"system\", \"content\": \"You are a helpful Geography tutor that generates concise summaries for different countries.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Give me a quick summary of Portugal.\"},\n",
    "       {\"role\": \"assistant\", \"content\": \"Portugal is a country in Europe that borders Spain. The capital city is Lisboa.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Give me a quick summary of Spain.\"},\n",
    "       {\"role\": \"assistant\", \"content\": \"Spain is a country in Europe that borders Portugal and France. The capital city is Madrid.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Give me a quick summary of France.\"},\n",
    "       {\"role\": \"assistant\", \"content\": \"France is a country in Europe that borders Spain and others. The capital city is Paris.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Give me a quick summary of the United States of America.\"},\n",
    "       {\"role\": \"assistant\", \"content\": \"The United States of America is a country in North America that borders Mexico and Canada. The capital city is Washington.\"},\n",
    "       {\"role\": \"user\", \"content\": \"Give me a quick summary of Greece.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39fbbf8-2dd1-445f-958a-8444cb0a93a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97401ecd-acf8-42df-ae17-d444b320e773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3704845-b6ff-4ea7-bbd0-498711504eca",
   "metadata": {},
   "source": [
    "## Multi-turn chat completions with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37ce897f-0a21-4bb3-b923-9df42c4d70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutable objects can be changed after creation (e.g., lists, dictionaries), while immutable objects cannot be altered once created (e.g., strings, tuples).\n"
     ]
    }
   ],
   "source": [
    "# vÃ­deo\n",
    "\n",
    "# In chat completions for SINGLE-TURN tasks, no content is sent to the assistant\n",
    "\n",
    "# Providing examples\n",
    "# - Steer model in the right direction\n",
    "# - Nothing surfaced to the end-user\n",
    "# - Example: Data Science Tutor Application\n",
    "#   - Provide examples of data science Q&A\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "system_prompt=\"\"\"You are a data science tutor who speaks concisely\"\"\"\n",
    "user_prompt_1=\"\"\"How do you define a Python list?\"\"\"\n",
    "assistant_prompt=\"\"\"Lists are defined by enclosing a comma-separated sequence of objects inside square brackets [ ].\"\"\"\n",
    "user_prompt_2=\"\"\"What is the difference between mutable and immutable objects?\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    # syste: control's the assistant behavior\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": system_prompt},\n",
    "\n",
    "    # Let's improve our data science tutor by providing an example.\n",
    "    # Between the system message & the user question, we'll add an user and assistant message to serve as an ideal example for the model.\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": user_prompt_1},\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": assistant_prompt},\n",
    "\n",
    "    # user question\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": user_prompt_2}\n",
    "     ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b289f6df-ea58-4b79-bc75-797ff00f9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Miguel! It's nice to meet you!\n"
     ]
    }
   ],
   "source": [
    "# Storing responses\n",
    "\n",
    "# Another common use for providing assistant messages is to store responses\n",
    "# - This way we can create a conversation history\n",
    "# - Create back-and-forth conversations\n",
    "# (this is exactly what goes on underneath chatbots like ChatGPT)\n",
    "\n",
    "\n",
    "# Building a conversation\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    # system: control's the assistant behavior\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"Reply in a nice way to the user.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"My name is Miguel.\"},\n",
    "    {\"role\": \"assistant\",\n",
    "     \"content\": \"Hi Miguel!\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"What is my name?\"}\n",
    "     ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67c7b33d-1cea-4338-9fd0-aa648691ca8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Why is Python so popular?\n",
      "Assistant:  Python is popular for several reasons:\n",
      "\n",
      "1. **Ease of Learning**: Python has a simple syntax that is easy for beginners to understand and use.\n",
      "\n",
      "2. **Versatility**: It can be used for a wide range of applications, from web development to data science, automation, and artificial intelligence.\n",
      "\n",
      "3. **Large Community**: Python has a vast community, which means plenty of resources, libraries, and frameworks are available to help developers.\n",
      "\n",
      "4. **Extensive Libraries**: Libraries like NumPy, Pandas, and TensorFlow make it powerful for data analysis and machine learning.\n",
      "\n",
      "5. **Cross-Platform**: Python works on various operating systems, making it accessible to many users.\n",
      "\n",
      "6. **Strong Support for Integration**: It easily integrates with other languages and technologies, enhancing its usability.\n",
      "\n",
      "These features combined make Python a go-to choice for many developers and data scientists. \n",
      "\n",
      "User:  Summarize this in one sentence.\n",
      "Assistant:  Python's popularity stems from its easy syntax, versatility across applications, strong community support, extensive libraries, cross-platform capability, and seamless integration with other technologies. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Coding a conversation\n",
    "\n",
    "messages=[{\"role\": \"system\",\n",
    "           \"content\": \"You are a data science tutor who provides short, simple explanations.\"}]\n",
    "\n",
    "user_questions = [\"Why is Python so popular?\", \"Summarize this in one sentence.\"]\n",
    "\n",
    "for q in user_questions:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages)\n",
    "\n",
    "    assistant_dict = {\"role\": \"assistant\",\n",
    "                      \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b0a7f-0e88-448d-bf86-75f7947ae580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33315c3-29ec-4bc4-814d-81952caae764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afc327b5-94f8-4e77-b647-cf377e737645",
   "metadata": {},
   "source": [
    "#### In-context learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89a554-77da-4fda-b4a1-d0c9198df8a8",
   "metadata": {},
   "source": [
    "For more complex use cases, the models lack the understanding or context of the problem to provide a suitable response from a prompt. In these cases, you need to provide examples to the model for it to learn from, so-called in-context learning.\n",
    "\n",
    "In this exercise, you'll improve on a Python programming tutor built on the OpenAI API by providing an example that the model can learn from.\n",
    "\n",
    "Here is an example of a user and assistant message you can use, but feel free to try out your own:\n",
    "\n",
    "User â†’ Explain what the min() Python function does.\n",
    "Assistant â†’ The min() function returns the smallest item from an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b18f8810-af30-4397-b851-d67514e27fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `type()` function in Python is used to determine the type of an object. It takes a single argument and returns the type of that object. This function is helpful for debugging, understanding what kind of data you are working with, and for making decisions in your code based on object types.\n",
      "\n",
      "### Syntax\n",
      "```python\n",
      "type(object)\n",
      "```\n",
      "\n",
      "### Parameters\n",
      "- `object`: The object whose type you want to check.\n",
      "\n",
      "### Returns\n",
      "- The function returns the type of the specified object, which is represented as a type object.\n",
      "\n",
      "### Examples\n",
      "\n",
      "1. **Checking the type of an integer:**\n",
      "   ```python\n",
      "   x = 10\n",
      "   print(type(x))  # Output: <class 'int'>\n",
      "   ```\n",
      "\n",
      "2. **Checking the type of a string:**\n",
      "   ```python\n",
      "   message = \"Hello, World!\"\n",
      "   print(type(message))  # Output: <class 'str'>\n",
      "   ```\n",
      "\n",
      "3. **Checking the type of a list:**\n",
      "   ```python\n",
      "   my_list = [1, 2, 3]\n",
      "   print(type(my_list))  # Output: <class 'list'>\n",
      "   ```\n",
      "\n",
      "4. **Checking the type of a custom class instance:**\n",
      "   ```python\n",
      "   class MyClass:\n",
      "       pass\n",
      "\n",
      "   obj = MyClass()\n",
      "   print(type(obj))  # Output: <class '__main__.MyClass'>\n",
      "   ```\n",
      "\n",
      "### Special Cases\n",
      "- If you pass `type()` no arguments (i.e., `type()`) it raises a `TypeError`.\n",
      "- You can also use `type()` to create new types dynamically, but that is a more advanced use case.\n",
      "\n",
      "In summary, `type()` is a built-in function in Python that gives you insight into what kind of data you're working with by returning the data type of an object.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the min() Python function does.\"},\n",
    "     {\"role\": \"assistant\", \"content\": \"\"\"The min() function returns the smallest item from an iterable.\"\"\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d80aa-a3f7-459b-b39b-d2592e112fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7273c-5ded-4da9-9a99-bf6130e3c452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d2635a6-a820-4a42-b382-c0396e6d2ac3",
   "metadata": {},
   "source": [
    "#### Creating an AI chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5a6d2fd9-e92e-4b5f-b45c-8b40b5e945b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Explain what pi is.\n",
      "Assistant:  Pi, denoted by the symbol \\( \\pi \\), is a mathematical constant that represents the ratio of a circle's circumference to its diameter. This means that for any circle, if you divide the length of the circumference (the distance around the circle) by the length of the diameter (the distance across the circle passing through the center), you will always get the same value: \\( \\pi \\).\n",
      "\n",
      "The value of \\( \\pi \\) is approximately 3.14159, but it is \n",
      "\n",
      "User:  Summarize this in two bullet points.\n",
      "Assistant:  - Pi (\\( \\pi \\)) is the ratio of a circle's circumference to its diameter, remaining constant for all circles.\n",
      "- Its approximate value is 3.14159, and it is an irrational number, meaning it has an infinite number of non-repeating decimal places. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb97cba-c086-4eaa-a617-597f1977cba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f529f8-eb87-4928-b09f-91e16b259ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7384470c-4f8e-45dc-bdca-e2ec761bd98d",
   "metadata": {},
   "source": [
    "# 3) Going Beyond Text Completions (Extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466d488b-5ce4-493e-bc63-7c7632120ef0",
   "metadata": {},
   "source": [
    "## Text moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "216458b3-e158-4ae3-b49c-2bf6e4fbdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('id', 'modr-BKqlqv7w1qe27I29ewWs4f2MgdiVI')\n",
      "('model', 'text-moderation-007')\n",
      "('results', [Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, illicit=None, illicit_violent=None, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_applied_input_types=None, category_scores=CategoryScores(harassment=0.000404250604333356, harassment_threatening=0.0006406133179552853, hate=0.00018232765432912856, hate_threatening=5.112017333885888e-06, illicit=None, illicit_violent=None, self_harm=0.0007804384804330766, self_harm_instructions=3.5095385442218685e-07, self_harm_intent=0.0002314060548087582, sexual=3.119655593764037e-05, sexual_minors=5.932895987825759e-07, violence=0.07933443784713745, violence_graphic=0.00023672528914175928, self-harm=0.0007804384804330766, sexual/minors=5.932895987825759e-07, hate/threatening=5.112017333885888e-06, violence/graphic=0.00023672528914175928, self-harm/intent=0.0002314060548087582, self-harm/instructions=3.5095385442218685e-07, harassment/threatening=0.0006406133179552853), flagged=False)])\n",
      "[None, None, None]\n",
      "\n",
      "\n",
      "[{'id': 'modr-BKqlqv7w1qe27I29ewWs4f2MgdiVI', 'model': 'text-moderation-007', 'results': [{'categories': {'harassment': False, 'harassment_threatening': False, 'hate': False, 'hate_threatening': False, 'illicit': None, 'illicit_violent': None, 'self_harm': False, 'self_harm_instructions': False, 'self_harm_intent': False, 'sexual': False, 'sexual_minors': False, 'violence': False, 'violence_graphic': False, 'self-harm': False, 'sexual/minors': False, 'hate/threatening': False, 'violence/graphic': False, 'self-harm/intent': False, 'self-harm/instructions': False, 'harassment/threatening': False}, 'category_applied_input_types': None, 'category_scores': {'harassment': 0.000404250604333356, 'harassment_threatening': 0.0006406133179552853, 'hate': 0.00018232765432912856, 'hate_threatening': 5.112017333885888e-06, 'illicit': None, 'illicit_violent': None, 'self_harm': 0.0007804384804330766, 'self_harm_instructions': 3.5095385442218685e-07, 'self_harm_intent': 0.0002314060548087582, 'sexual': 3.119655593764037e-05, 'sexual_minors': 5.932895987825759e-07, 'violence': 0.07933443784713745, 'violence_graphic': 0.00023672528914175928, 'self-harm': 0.0007804384804330766, 'sexual/minors': 5.932895987825759e-07, 'hate/threatening': 5.112017333885888e-06, 'violence/graphic': 0.00023672528914175928, 'self-harm/intent': 0.0002314060548087582, 'self-harm/instructions': 3.5095385442218685e-07, 'harassment/threatening': 0.0006406133179552853}, 'flagged': False}]}]\n"
     ]
    }
   ],
   "source": [
    "#vÃ­deo\n",
    "\n",
    "# Text moderation\n",
    "# - Identifying inappropriate content\n",
    "\n",
    "#   - Manual moderating by hand -> very time consuming\n",
    "#   - Keyword pattern matching -> lacks nuance and understanding of context\n",
    "\n",
    "#   - OpenAI has created moderationm models:\n",
    "#     - Identify violations of terms or use\n",
    "#     - Differentiate violation type by category:\n",
    "#        - Violence\n",
    "#        - Hate Speech\n",
    "\n",
    "# Creating a moderation request\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"I could kill for a hamburguer\"\n",
    ")\n",
    "\n",
    "# more readable\n",
    "print([print(i) for i in response])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# same but as dictionary\n",
    "print([response.model_dump()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50e777b9-cf0f-4eb1-a3bd-5ad47ec41424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'categories': {'harassment': False,\n",
       "   'harassment_threatening': False,\n",
       "   'hate': False,\n",
       "   'hate_threatening': False,\n",
       "   'illicit': None,\n",
       "   'illicit_violent': None,\n",
       "   'self_harm': False,\n",
       "   'self_harm_instructions': False,\n",
       "   'self_harm_intent': False,\n",
       "   'sexual': False,\n",
       "   'sexual_minors': False,\n",
       "   'violence': False,\n",
       "   'violence_graphic': False,\n",
       "   'self-harm': False,\n",
       "   'sexual/minors': False,\n",
       "   'hate/threatening': False,\n",
       "   'violence/graphic': False,\n",
       "   'self-harm/intent': False,\n",
       "   'self-harm/instructions': False,\n",
       "   'harassment/threatening': False},\n",
       "  'category_applied_input_types': None,\n",
       "  'category_scores': {'harassment': 0.000404250604333356,\n",
       "   'harassment_threatening': 0.0006406133179552853,\n",
       "   'hate': 0.00018232765432912856,\n",
       "   'hate_threatening': 5.112017333885888e-06,\n",
       "   'illicit': None,\n",
       "   'illicit_violent': None,\n",
       "   'self_harm': 0.0007804384804330766,\n",
       "   'self_harm_instructions': 3.5095385442218685e-07,\n",
       "   'self_harm_intent': 0.0002314060548087582,\n",
       "   'sexual': 3.119655593764037e-05,\n",
       "   'sexual_minors': 5.932895987825759e-07,\n",
       "   'violence': 0.07933443784713745,\n",
       "   'violence_graphic': 0.00023672528914175928,\n",
       "   'self-harm': 0.0007804384804330766,\n",
       "   'sexual/minors': 5.932895987825759e-07,\n",
       "   'hate/threatening': 5.112017333885888e-06,\n",
       "   'violence/graphic': 0.00023672528914175928,\n",
       "   'self-harm/intent': 0.0002314060548087582,\n",
       "   'self-harm/instructions': 3.5095385442218685e-07,\n",
       "   'harassment/threatening': 0.0006406133179552853},\n",
       "  'flagged': False}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) \"categories\": True / False \n",
    "\n",
    "# 2) \"category_scores\": Confidence of a violation\n",
    "# Larger numbers => greater certainty of violation; Numbers != probabilities (for instance look at value of \"violence\" in this case)\n",
    "# Determine appropriate thresholds for each use case\n",
    "# Stricter thresholds may result in fewer False Negatives\n",
    "# More lenient threshols may result in fewer False Positives\n",
    "\n",
    "# 3) \"flagged\": True / False \n",
    "\n",
    "response.model_dump()[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be7317-c71b-4140-99f7-701f7c9467ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f76110da-8e92-44dc-b2c0-fe422c39065d",
   "metadata": {},
   "source": [
    "#### Requesting moderation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17dc696d-170e-47a3-83c0-ce73d3c97133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flagged: False \n",
      "\n",
      "CategoryScores(harassment=5.243551186140394e-06, harassment_threatening=1.1516095810293336e-06, hate=4.767837526742369e-05, hate_threatening=3.2021056028952444e-08, illicit=None, illicit_violent=None, self_harm=9.466615438213921e-07, self_harm_instructions=5.426785065765216e-08, self_harm_intent=1.5536235764557205e-07, sexual=3.545879735611379e-06, sexual_minors=1.1304399549771915e-06, violence=0.0001064608441083692, violence_graphic=1.086988686438417e-05, self-harm=9.466615438213921e-07, sexual/minors=1.1304399549771915e-06, hate/threatening=3.2021056028952444e-08, violence/graphic=1.086988686438417e-05, self-harm/intent=1.5536235764557205e-07, self-harm/instructions=5.426785065765216e-08, harassment/threatening=1.1516095810293336e-06)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'harassment': 5.243551186140394e-06,\n",
       " 'harassment_threatening': 1.1516095810293336e-06,\n",
       " 'hate': 4.767837526742369e-05,\n",
       " 'hate_threatening': 3.2021056028952444e-08,\n",
       " 'illicit': None,\n",
       " 'illicit_violent': None,\n",
       " 'self_harm': 9.466615438213921e-07,\n",
       " 'self_harm_instructions': 5.426785065765216e-08,\n",
       " 'self_harm_intent': 1.5536235764557205e-07,\n",
       " 'sexual': 3.545879735611379e-06,\n",
       " 'sexual_minors': 1.1304399549771915e-06,\n",
       " 'violence': 0.0001064608441083692,\n",
       " 'violence_graphic': 1.086988686438417e-05,\n",
       " 'self-harm': 9.466615438213921e-07,\n",
       " 'sexual/minors': 1.1304399549771915e-06,\n",
       " 'hate/threatening': 3.2021056028952444e-08,\n",
       " 'violence/graphic': 1.086988686438417e-05,\n",
       " 'self-harm/intent': 1.5536235764557205e-07,\n",
       " 'self-harm/instructions': 5.426785065765216e-08,\n",
       " 'harassment/threatening': 1.1516095810293336e-06}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"My favorite book is To Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Check \"flagged\"\n",
    "print(\"flagged:\", response.results[0].flagged, \"\\n\")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.results[0].category_scores)\n",
    "\n",
    "# category_scores in list form, for readability\n",
    "response.model_dump()[\"results\"][0][\"category_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce54eb6-9a13-4dd4-9c8f-7600449f7636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2bfef-7446-4836-b6df-0b4480be398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34b2c09e-1d1c-4a2b-a9ae-245fe1c1f368",
   "metadata": {},
   "source": [
    "#### Examining moderation category scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "daa433aa-4f80-4441-b579-93081854a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Last exercise results):\n",
    "\n",
    "# The model believes that there are no violations, as all categories are close to 0. (True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd74d13-7778-4c51-8b9b-2b6925da86aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92ed4145-5174-40a4-832c-82a8c4263957",
   "metadata": {},
   "source": [
    "## Speech-to-text Transcription with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "265df10e-c638-4d38-aafa-6c924241bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='Test, test, test.')\n",
      "Test, test, test.\n"
     ]
    }
   ],
   "source": [
    "# vÃ­deo\n",
    "\n",
    "# Whisper\n",
    "\n",
    "audio_file = open(data_folder + \"Teste.m4a\", \"rb\") # rb (mode): read binary\n",
    "\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "print(response)\n",
    "print(response.text)\n",
    "\n",
    "# Note: Don't use sensitive or confidential recordings\n",
    "\n",
    "# Transcribing non-English languages (list has essentially all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ad10c-08a0-415f-a8ce-068ded0037df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a18a0b7-823c-4fe0-997c-5afc29a92b79",
   "metadata": {},
   "source": [
    "#### Creating a podcast transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bb1490bb-cbf5-45b2-8d59-8d79c808f7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='Hello, my name is Miguel.')\n",
      "Hello, my name is Miguel.\n"
     ]
    }
   ],
   "source": [
    "# English audio file\n",
    "audio_file_EN = open(data_folder + \"Hello name Miguel.m4a\", \"rb\")\n",
    "\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file_EN)\n",
    "\n",
    "print(response)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20be7adb-ba26-491b-bfec-3c87f535a67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "448cf30a-7534-44b0-9ef8-195f9ef5015b",
   "metadata": {},
   "source": [
    "#### Transcribing a non-English language (Portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cdc23a42-5dfc-4865-aa30-648b2505f839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription(text='All that, my name is Miguel.')\n",
      "All that, my name is Miguel.\n"
     ]
    }
   ],
   "source": [
    "# Portuguese audio file\n",
    "audio_file_PT = open(data_folder + \"Nome Ã© Miguel.m4a\", \"rb\")\n",
    "\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file_PT)\n",
    "\n",
    "print(response)\n",
    "print(response.text) # o audio diz \"OlÃ¡, o meu nome Ã© Miguel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f8ec4-dcae-4330-801c-803ef1dcc896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3587d-ce72-4b05-98f9-b4a66184ff12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbb65bab-bcbb-4587-81ce-6830926f8ada",
   "metadata": {},
   "source": [
    "## Speech Translation with Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7fa9a9ea-6c5d-4b52-a756-8ed7abe83b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All that, my name is Miguel.\n"
     ]
    }
   ],
   "source": [
    "# vÃ­deo\n",
    "\n",
    "# Whisper's translation capabilities\n",
    "# - Translate and transcribe audio\n",
    "# - Currently limited to English transcripts (we can transcribe German into English, but not German into French)\n",
    "# - Supports mp3, mp4, mpeg, m4a, wav and webm (up to 25MB limit)\n",
    "\n",
    "\n",
    "# Translating audio\n",
    "\n",
    "# open non-english audio\n",
    "audio_file_PT = open(data_folder + \"Nome Ã© Miguel.m4a\", \"rb\")\n",
    "\n",
    "# .translations (and not .transcriptions)\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file_PT)\n",
    "\n",
    "print(response.text) # not perfect\n",
    "\n",
    "# --> Performance can vary wildly, depending on:\n",
    "    # - audio quality\n",
    "    # - audio language\n",
    "    # - Model's knowledge of the subject matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ee15b7a2-fed0-4b68-b470-5372d691b567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All that aside, my name is Miguel.\n"
     ]
    }
   ],
   "source": [
    "# --> Bringing prompts into the mix\n",
    "# - Can provide prompt to the model (optional)\n",
    "# - Improve response quality by\n",
    "#    - Providing an example of desired style.\n",
    "\n",
    "# Example: Retaining filler words (like \"ahhmmm\", \"hummmm\", etc)\n",
    "prompt = \"\"\"Ok, ummm... this is what we should do, like, to uhhhh... increase revenue.\"\"\"\n",
    "\n",
    "# Example: Provide context\n",
    "prompt = \"\"\"A discussion on how to incerease revenue.\"\"\"\n",
    "\n",
    "\n",
    "# Adding in a prompt (tentar corrigir os erros)\n",
    "\n",
    "audio_file_PT = open(data_folder + \"Nome Ã© Miguel.m4a\", \"rb\")\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file_PT)\n",
    "translation_to_en = response.text\n",
    "\n",
    "prompt=\"\"\"The transcript is about a personal introduction. \n",
    "Infer the mistakes and adjust the following translated text (it was translated from Portuguese to English): {}.\n",
    "Show only one final output - your best one.\"\"\".format(translation_to_en)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "    \n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f802e-92a2-454d-97db-e12a84ada33a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e92650d-6250-46a0-91d8-e1803a086f71",
   "metadata": {},
   "source": [
    "#### Translating Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e64b1ed5-7038-4191-9a9d-b0a3fec71941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All that, my name is Miguel.\n"
     ]
    }
   ],
   "source": [
    "audio_file_PT = open(data_folder + \"Nome Ã© Miguel.m4a\", \"rb\")\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file_PT)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d595a6c-7b6c-4743-8581-2b3c6f9cc879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb6eae19-659c-4837-b4b7-a4b7828bba51",
   "metadata": {},
   "source": [
    "#### Translating with prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0e23c-67ae-4d46-a3ef-bedaf64696c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd532b-3996-46d4-b139-eccce53497c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6fad4-7fd6-4960-aa8d-aa6d66533798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e68a7ee-b320-4f69-8dcf-63dbac0a1b24",
   "metadata": {},
   "source": [
    "## Combining models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a469e21-9c38-4418-907a-5b3732d471a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2426559-74c2-461a-8e18-163fb5575e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e32571c-9dcc-4063-adbb-e63e0a53e1f3",
   "metadata": {},
   "source": [
    "#### Identifying audio languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e4c3a-f6a2-480f-b78b-2969d9312a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eff41a-a0da-4c5e-85be-74afdf15d76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acc29233-447d-48c4-b038-c98030059bc5",
   "metadata": {},
   "source": [
    "#### Creating meeting summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e9626-cd40-4a8d-84fb-37ffb9749be0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9727fa-5213-4621-819b-ae23e469cd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb83779-2127-4344-b48a-45b00b370833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d033ac9e-f06b-422c-8b88-e6674765868e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
